{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a609bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce9d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "startups_df = pd.read_excel('startups.xlsx', sheet_name='Request 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6db7758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Description</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Industry2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Enclarity Inc</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>Enclarity, Inc. is a United States-based healt...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Computer Software and Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ocean Entertainment Inc</td>\n",
       "      <td>2014-01-16</td>\n",
       "      <td>Ocean Entertainment Inc. is introducing the fi...</td>\n",
       "      <td>Non-High Technology</td>\n",
       "      <td>Consumer Related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ocean Entertainment Inc</td>\n",
       "      <td>2014-01-16</td>\n",
       "      <td>Ocean Entertainment Inc. is introducing the fi...</td>\n",
       "      <td>Non-High Technology</td>\n",
       "      <td>Consumer Related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Hengyang Jinzeli Special Allop Co Ltd</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>Hengyang Jinzeli Special Alloy Co., Ltd. is a ...</td>\n",
       "      <td>Non-High Technology</td>\n",
       "      <td>Industrial/Energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Verge Solutions LLC</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>Verge Solutions LLC is a United States-based c...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Computer Software and Services</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                           Company Name       Date  \\\n",
       "0   1                          Enclarity Inc 2005-01-01   \n",
       "1   2                Ocean Entertainment Inc 2014-01-16   \n",
       "2   3                Ocean Entertainment Inc 2014-01-16   \n",
       "3   4  Hengyang Jinzeli Special Allop Co Ltd 1999-12-01   \n",
       "4   5                    Verge Solutions LLC 2001-01-01   \n",
       "\n",
       "                                         Description                Industry  \\\n",
       "0  Enclarity, Inc. is a United States-based healt...  Information Technology   \n",
       "1  Ocean Entertainment Inc. is introducing the fi...     Non-High Technology   \n",
       "2  Ocean Entertainment Inc. is introducing the fi...     Non-High Technology   \n",
       "3  Hengyang Jinzeli Special Alloy Co., Ltd. is a ...     Non-High Technology   \n",
       "4  Verge Solutions LLC is a United States-based c...  Information Technology   \n",
       "\n",
       "                        Industry2  \n",
       "0  Computer Software and Services  \n",
       "1                Consumer Related  \n",
       "2                Consumer Related  \n",
       "3               Industrial/Energy  \n",
       "4  Computer Software and Services  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startups_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8840404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    enclarity united statesbased healthcare inform...\n",
       "1    ocean entertainment introducing first high tec...\n",
       "2    ocean entertainment introducing first high tec...\n",
       "3    hengyang jinzeli special alloy chinabased comp...\n",
       "4    verge solution united statesbased company deve...\n",
       "5    cadre technology united statesbased company pr...\n",
       "6    covario united statesbased independent search ...\n",
       "7    latis network also known stillsecure united st...\n",
       "8    cloudblue technology united statesbased compan...\n",
       "9    provides online commercial property informatio...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    #converting the text into lower case\n",
    "    text = text.lower() \n",
    "    #remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    #remove the stopwords \n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "    text = ' '.join(filtered_text)\n",
    "    #Apply lemmatization\n",
    "    le=WordNetLemmatizer()\n",
    "    tokens=[le.lemmatize(w) for w in word_tokens if w not in stop_words and len(w)>3]\n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text\n",
    "\n",
    "startups_df['Description'] = startups_df['Description'].apply(clean_text)\n",
    "startups_df['Description'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71c7e5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60089, 1000)\n",
      "  (0, 578)\t0.07666078205302546\n",
      "  (0, 649)\t0.06628732984908636\n",
      "  (0, 633)\t0.1114309150778018\n",
      "  (0, 686)\t0.2131205891354204\n",
      "  (0, 265)\t0.05261161672562631\n",
      "  (0, 319)\t0.12298781629724369\n",
      "  (0, 77)\t0.06147150428162164\n",
      "  (0, 8)\t0.04918164222581738\n",
      "  (0, 764)\t0.06831761399118941\n",
      "  (0, 480)\t0.07248757529051318\n",
      "  (0, 41)\t0.05242260042267137\n",
      "  (0, 990)\t0.057703511031325136\n",
      "  (0, 43)\t0.07014694730730867\n",
      "  (0, 473)\t0.05955805007420204\n",
      "  (0, 413)\t0.06929308266431074\n",
      "  (0, 823)\t0.12392758583169272\n",
      "  (0, 647)\t0.06533178252385463\n",
      "  (0, 623)\t0.12313940434957549\n",
      "  (0, 276)\t0.044500523091125635\n",
      "  (0, 804)\t0.05998687612115804\n",
      "  (0, 535)\t0.05866243324940094\n",
      "  (0, 926)\t0.053956026199345926\n",
      "  (0, 706)\t0.06983356193209303\n",
      "  (0, 118)\t0.07120671049041384\n",
      "  (0, 147)\t0.06873488750129904\n",
      "  :\t:\n",
      "  (60086, 1)\t0.2191043591685591\n",
      "  (60086, 847)\t0.1316392061804365\n",
      "  (60086, 574)\t0.1918629742700391\n",
      "  (60087, 618)\t0.40502166693689146\n",
      "  (60087, 395)\t0.40702005712155154\n",
      "  (60087, 393)\t0.41385947278176455\n",
      "  (60087, 193)\t0.34837658877308275\n",
      "  (60087, 558)\t0.26351610149699195\n",
      "  (60087, 639)\t0.18827942921050225\n",
      "  (60087, 693)\t0.1634917326244496\n",
      "  (60087, 293)\t0.2931660149441895\n",
      "  (60087, 154)\t0.2218676078854649\n",
      "  (60087, 904)\t0.2973618562087481\n",
      "  (60087, 823)\t0.131793101649738\n",
      "  (60087, 185)\t0.07114592630688986\n",
      "  (60088, 270)\t0.33870446236775276\n",
      "  (60088, 828)\t0.35654098869866174\n",
      "  (60088, 304)\t0.5723573347186208\n",
      "  (60088, 455)\t0.338628871345816\n",
      "  (60088, 955)\t0.28594476024655424\n",
      "  (60088, 330)\t0.17402950697684189\n",
      "  (60088, 339)\t0.3215998453123827\n",
      "  (60088, 904)\t0.14663094275445293\n",
      "  (60088, 781)\t0.2433621027338719\n",
      "  (60088, 185)\t0.1403299586641629\n"
     ]
    }
   ],
   "source": [
    "# create TF-IDF vector, apply stop words, keep only 1000 features (1000 columns)\n",
    "vect =TfidfVectorizer(stop_words=list(stop_words),max_features=1000)\n",
    "vect_text=vect.fit_transform(startups_df['Description'])\n",
    "# check the dimension and content of vect_text\n",
    "print(vect_text.shape)\n",
    "print(vect_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd8b8f9",
   "metadata": {},
   "source": [
    "### LDA topic modeling for 3 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e00a0de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 15.854220867156982 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Applying the classical LDA topic-modeling for 3 topics\n",
    "start_time = time.time()\n",
    "lda_model=LatentDirichletAllocation(n_components=3,random_state=42,n_jobs=-1)\n",
    "lda_top=lda_model.fit_transform(vect_text)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31d7934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60089, 3)\n",
      "[[0.06843945 0.05650093 0.87505962]\n",
      " [0.34286984 0.18709981 0.47003034]\n",
      " [0.34433222 0.19096773 0.46470005]\n",
      " ...\n",
      " [0.69775733 0.16254875 0.13969392]\n",
      " [0.08810856 0.8263619  0.08552955]\n",
      " [0.81323908 0.0915391  0.09522182]]\n"
     ]
    }
   ],
   "source": [
    "print(lda_top.shape)  # (no_of_doc,no_of_topics)\n",
    "print(lda_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df79aa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: \n",
      "Topic  0 :  8.7682743414047 %\n",
      "Topic  1 :  67.72619846360291 %\n",
      "Topic  2 :  23.505527194992393 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Document 0: \")\n",
    "for i,topic in enumerate(lda_top[9]):\n",
    "  print(\"Topic \",i,\": \",topic*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "480af46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Adding the predicted topics to the startups dataframe\n",
    "topics = np.argmax(lda_top, axis=1)\n",
    "print(topics)\n",
    "startups_df['Predicted_Topic'] = None\n",
    "for i in range(0, len(startups_df)):\n",
    "    topic_str = \"Topic\" + str(topics[i])\n",
    "    startups_df.loc[i, 'Predicted_Topic'] = topic_str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3dfc687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic2    24808\n",
       "Topic1    17909\n",
       "Topic0    17372\n",
       "Name: Predicted_Topic, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startups_df['Predicted_Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70584f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Industry Predicted_Topic  Counts  Proportion\n",
      "0  Information Technology          Topic0    4081    0.113557\n",
      "1  Information Technology          Topic1    9278    0.258167\n",
      "2  Information Technology          Topic2   22579    0.628276\n"
     ]
    }
   ],
   "source": [
    "#Finding the most similar topic to the given industry \"Information Technology\"\n",
    "grouped_counts = startups_df.groupby(['Industry', 'Predicted_Topic']).size().reset_index(name='Counts')\n",
    "total_IT_counts = grouped_counts[grouped_counts['Industry'] == 'Information Technology']['Counts'].sum()\n",
    "grouped_counts['Proportion'] = grouped_counts.apply(lambda row: row['Counts'] / total_IT_counts if row['Industry'] == 'Information Technology' else None, axis=1)\n",
    "print(grouped_counts[grouped_counts['Industry'] == 'Information Technology'])\n",
    "#From the below table it is clear that Topic2 is the most similar to Industry Information Technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f381002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>Predicted_Topic</th>\n",
       "      <th>Counts</th>\n",
       "      <th>Proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Topic0</td>\n",
       "      <td>4081</td>\n",
       "      <td>0.113557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Topic1</td>\n",
       "      <td>9278</td>\n",
       "      <td>0.258167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Topic2</td>\n",
       "      <td>22579</td>\n",
       "      <td>0.628276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Medical/Health/Life Science</td>\n",
       "      <td>Topic0</td>\n",
       "      <td>7471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Medical/Health/Life Science</td>\n",
       "      <td>Topic1</td>\n",
       "      <td>546</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Medical/Health/Life Science</td>\n",
       "      <td>Topic2</td>\n",
       "      <td>563</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Non-High Technology</td>\n",
       "      <td>Topic0</td>\n",
       "      <td>5820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Non-High Technology</td>\n",
       "      <td>Topic1</td>\n",
       "      <td>8085</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Non-High Technology</td>\n",
       "      <td>Topic2</td>\n",
       "      <td>1666</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Industry Predicted_Topic  Counts  Proportion\n",
       "0       Information Technology          Topic0    4081    0.113557\n",
       "1       Information Technology          Topic1    9278    0.258167\n",
       "2       Information Technology          Topic2   22579    0.628276\n",
       "3  Medical/Health/Life Science          Topic0    7471         NaN\n",
       "4  Medical/Health/Life Science          Topic1     546         NaN\n",
       "5  Medical/Health/Life Science          Topic2     563         NaN\n",
       "6          Non-High Technology          Topic0    5820         NaN\n",
       "7          Non-High Technology          Topic1    8085         NaN\n",
       "8          Non-High Technology          Topic2    1666         NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e659b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives =  22579\n",
      "False Positives =  2229\n",
      "False Negatives =  13359\n",
      "True Negatives =  21922\n",
      "TP+TN+FP+TN =  60089\n",
      "\n",
      "3-topic Modelling with LDA\n",
      "\n",
      "Precision =  0.910149951628507\n",
      "Recall =  0.6282764761533752\n"
     ]
    }
   ],
   "source": [
    "#calculating precision and recall of Industry Information Technology\n",
    "\n",
    "tp = grouped_counts[(grouped_counts['Industry'] == 'Information Technology') & (grouped_counts['Predicted_Topic'] == 'Topic2')]['Counts'].sum()#True Postives calculation\n",
    "fp = grouped_counts[(grouped_counts['Industry'] != 'Information Technology') & (grouped_counts['Predicted_Topic'] == 'Topic2')]['Counts'].sum()\n",
    "fn = grouped_counts[(grouped_counts['Industry'] == 'Information Technology') & (grouped_counts['Predicted_Topic'] != 'Topic2')]['Counts'].sum()\n",
    "tn = grouped_counts[(grouped_counts['Industry'] != 'Information Technology') & (grouped_counts['Predicted_Topic'] != 'Topic2')]['Counts'].sum()\n",
    "\n",
    "print(\"True Positives = \", tp)\n",
    "print(\"False Positives = \",fp)\n",
    "print(\"False Negatives = \",fn)\n",
    "print(\"True Negatives = \",tn)\n",
    "print(\"TP+TN+FP+TN = \", tp+tn+fn+fp)\n",
    "\n",
    "#calculate precision\n",
    "precision = tp/(tp+fp)\n",
    "#calculate recall\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(\"\\n3-topic Modelling with LDA\\n\")\n",
    "print(\"Precision = \", precision)\n",
    "print(\"Recall = \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d897a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "company product technology system medical development manufacture develops research treatment \n",
      "\n",
      "Topic 1: \n",
      "company service operates engaged business online provides product offer chinabased \n",
      "\n",
      "Topic 2: \n",
      "company software solution platform data provides service user application united \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most important words (top 10) for each topic\n",
    "vocab = vect.get_feature_names_out()\n",
    "\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10] # this is where you change the top 10 to topX\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c84b8c",
   "metadata": {},
   "source": [
    "### LDA topic modelling for 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9078392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 10.886080026626587 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Applying the classical LDA topic-modeling for 3 topics\n",
    "start_time = time.time()\n",
    "lda_model=LatentDirichletAllocation(n_components=10,random_state=42,n_jobs=-1)\n",
    "lda_top=lda_model.fit_transform(vect_text)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a62b2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60089, 10)\n",
      "[[0.01580244 0.01580247 0.01580496 ... 0.85777522 0.01580385 0.01580245]\n",
      " [0.01451276 0.0145164  0.58466519 ... 0.01451321 0.01451413 0.01451187]\n",
      " [0.01464448 0.01464818 0.58164035 ... 0.01464489 0.01464584 0.01464355]\n",
      " ...\n",
      " [0.02543878 0.02540887 0.0254035  ... 0.02540637 0.02542085 0.02540337]\n",
      " [0.35717625 0.02378617 0.02378466 ... 0.0237856  0.0237843  0.45253947]\n",
      " [0.17522868 0.02552638 0.02552787 ... 0.02553444 0.02553169 0.02552516]]\n"
     ]
    }
   ],
   "source": [
    "print(lda_top.shape)  # (no_of_doc,no_of_topics)\n",
    "print(lda_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53824686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: \n",
      "Topic  0 :  1.459473646250183 %\n",
      "Topic  1 :  1.4595883737527218 %\n",
      "Topic  2 :  1.4597166810091065 %\n",
      "Topic  3 :  1.4594148177155974 %\n",
      "Topic  4 :  1.4591601356368409 %\n",
      "Topic  5 :  47.21702547880194 %\n",
      "Topic  6 :  1.459297713860205 %\n",
      "Topic  7 :  1.4596330857614523 %\n",
      "Topic  8 :  1.459461565667403 %\n",
      "Topic  9 :  41.10722850154454 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Document 0: \")\n",
    "for i,topic in enumerate(lda_top[9]):\n",
    "  print(\"Topic \",i,\": \",topic*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6917a2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 2 ... 3 9 4]\n"
     ]
    }
   ],
   "source": [
    "# Adding the predicted topics to the startups dataframe\n",
    "topics2 = np.argmax(lda_top, axis=1)\n",
    "print(topics2)\n",
    "startups_df['Predicted_Topic_2'] = None\n",
    "for i in range(0, len(startups_df)):\n",
    "    topic_str = \"Topic\" + str(topics2[i])\n",
    "    startups_df.loc[i, 'Predicted_Topic_2'] = topic_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f96caa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic7    11304\n",
       "Topic2     8330\n",
       "Topic4     7238\n",
       "Topic3     6905\n",
       "Topic5     4958\n",
       "Topic8     4863\n",
       "Topic0     4452\n",
       "Topic9     4313\n",
       "Topic6     4022\n",
       "Topic1     3704\n",
       "Name: Predicted_Topic_2, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startups_df['Predicted_Topic_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54304a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Industry2 Predicted_Topic_2  Counts  Proportion\n",
      "30  Computer Software and Services            Topic0    1091    0.070647\n",
      "31  Computer Software and Services            Topic1     784    0.050767\n",
      "32  Computer Software and Services            Topic2    3428    0.221978\n",
      "33  Computer Software and Services            Topic3     277    0.017937\n",
      "34  Computer Software and Services            Topic4     350    0.022664\n",
      "35  Computer Software and Services            Topic5     363    0.023506\n",
      "36  Computer Software and Services            Topic6     159    0.010296\n",
      "37  Computer Software and Services            Topic7    7286    0.471800\n",
      "38  Computer Software and Services            Topic8    1005    0.065078\n",
      "39  Computer Software and Services            Topic9     700    0.045328\n"
     ]
    }
   ],
   "source": [
    "#Finding the most similar topic to the given industry2 \"Computer Software and Services\"\n",
    "grouped_counts_t2 = startups_df.groupby(['Industry2', 'Predicted_Topic_2']).size().reset_index(name='Counts')\n",
    "total_CSS_counts = grouped_counts_t2[grouped_counts_t2['Industry2'] == 'Computer Software and Services']['Counts'].sum()\n",
    "grouped_counts_t2['Proportion'] = grouped_counts_t2.apply(lambda row: row['Counts'] / total_CSS_counts if row['Industry2'] == 'Computer Software and Services' else None, axis=1)\n",
    "print(grouped_counts_t2[grouped_counts_t2['Industry2'] == 'Computer Software and Services']) \n",
    "#From the below table it is clear that Topic7 is the most similar to industry2 \"Computer Software and Services\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fd2e4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives =  7286\n",
      "False Positives =  4018\n",
      "False Negatives =  8157\n",
      "True Negatives =  40628\n",
      "TP+TN+FP+TN =  60089\n",
      "\n",
      "10-topic modelling with LDA\n",
      "\n",
      "Precision =  0.644550601556971\n",
      "Recall =  0.4717995208184938\n"
     ]
    }
   ],
   "source": [
    "#calculating precision and recall of industry2 \"Computer Software and Services\"\n",
    "\n",
    "tp2 = grouped_counts_t2[(grouped_counts_t2['Industry2'] == 'Computer Software and Services') & (grouped_counts_t2['Predicted_Topic_2'] == 'Topic7')]['Counts'].sum()#True Postives calculation\n",
    "fp2 = grouped_counts_t2[(grouped_counts_t2['Industry2'] != 'Computer Software and Services') & (grouped_counts_t2['Predicted_Topic_2'] == 'Topic7')]['Counts'].sum()\n",
    "fn2 = grouped_counts_t2[(grouped_counts_t2['Industry2'] == 'Computer Software and Services') & (grouped_counts_t2['Predicted_Topic_2'] != 'Topic7')]['Counts'].sum()\n",
    "tn2 = grouped_counts_t2[(grouped_counts_t2['Industry2'] != 'Computer Software and Services') & (grouped_counts_t2['Predicted_Topic_2'] != 'Topic7')]['Counts'].sum()\n",
    "\n",
    "print(\"True Positives = \", tp2)\n",
    "print(\"False Positives = \",fp2)\n",
    "print(\"False Negatives = \",fn2)\n",
    "print(\"True Negatives = \",tn2)\n",
    "print(\"TP+TN+FP+TN = \", tp2+tn2+fn2+fp2)\n",
    "\n",
    "#calculate precision\n",
    "precision2 = tp2/(tp2+fp2)\n",
    "#calculate recall\n",
    "recall2 = tp2/(tp2+fn2)\n",
    "\n",
    "print(\"\\n10-topic modelling with LDA\\n\")\n",
    "print(\"Precision = \", precision2)\n",
    "print(\"Recall = \", recall2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6103e41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "chinabased engaged mainly technology company development provision service beijing product \n",
      "\n",
      "Topic 1: \n",
      "financial company service loan payment education provides credit bank student \n",
      "\n",
      "Topic 2: \n",
      "company user mobile platform game content application video provides social \n",
      "\n",
      "Topic 3: \n",
      "company product system manufacture technology material energy equipment power water \n",
      "\n",
      "Topic 4: \n",
      "company disease drug medical treatment patient therapeutic therapy cancer product \n",
      "\n",
      "Topic 5: \n",
      "company service energy project investment operates property management estate provides \n",
      "\n",
      "Topic 6: \n",
      "company product brand offer operates online accessory care home others \n",
      "\n",
      "Topic 7: \n",
      "company data software solution management service platform provides united statesbased \n",
      "\n",
      "Topic 8: \n",
      "network wireless service solution company communication internet mobile develops system \n",
      "\n",
      "Topic 9: \n",
      "company food online service offer restaurant provides operates product platform \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most important words (top 10) for each topic\n",
    "vocab = vect.get_feature_names_out()\n",
    "\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10] # this is where you change the top 10 to topX\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec2ca5",
   "metadata": {},
   "source": [
    "### GridSearch CV with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b211308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 523.822723865509 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "search_params = {'n_components': [15, 30], 'learning_decay': [.5, .9]}\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=3,               # Number of topics\n",
    "                                max_iter=10,               # Max learning iterations\n",
    "                                learning_method='online',   \n",
    "                                random_state=100,          # Random state\n",
    "                                batch_size=128,            # n docs in each learning iter\n",
    "                                evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                n_jobs = -1,               # Use all available CPUs\n",
    "                                )\n",
    "\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "model.fit(vect_text)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b763236b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.9, 'n_components': 15}\n",
      "Best Log Likelihood Score:  -363083.0114933131\n",
      "Model Perplexity:  1350.58003762671\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(vect_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df56e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 757.1203529834747 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "search_params = {'n_components': [15, 30], 'learning_decay': [.5, .9]}\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=10,               # Number of topics\n",
    "                                max_iter=10,               # Max learning iterations\n",
    "                                learning_method='online',   \n",
    "                                random_state=100,          # Random state\n",
    "                                batch_size=128,            # n docs in each learning iter\n",
    "                                evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                n_jobs = -1,               # Use all available CPUs\n",
    "                                )\n",
    "\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "model.fit(vect_text)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90cc0038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.9, 'n_components': 15}\n",
      "Best Log Likelihood Score:  -363083.0114933131\n",
      "Model Perplexity:  1350.58003762671\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(vect_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c44aaf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
