{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe3280d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ad4ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/balubabu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5dadf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detecting the encoding of the given file\n",
    "with open('zacks_arguments.csv', 'rb') as file:\n",
    "    sample = file.read(10000)  # Read first 10000 bytes as a sample\n",
    "    detected = chardet.detect(sample)\n",
    "    encoding = detected['encoding']\n",
    "df = pd.read_csv('zacks_arguments.csv', encoding=encoding)\n",
    "#Reading the files into the dataframe\n",
    "zacks_args_df = pd.read_csv('zacks_arguments.csv', encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4779a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the positive and negative word lists into the dataframe \n",
    "column_positive_words = ['Postive_Words']\n",
    "column_negative_words = ['Negative_Words']\n",
    "positive_words_df = pd.read_csv('LM2018P.csv', header=None, names=column_positive_words)\n",
    "negative_words_df = pd.read_csv('LM2018N.csv', header=None, names=column_negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "803ed1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.\tConvert all letters to lowercase\n",
    "zacks_args_df['arguments_clean'] = zacks_args_df['arguments_clean'].str.lower()\n",
    "positive_words_df['Postive_Words'] = positive_words_df['Postive_Words'].str.lower()\n",
    "negative_words_df['Negative_Words'] = negative_words_df['Negative_Words'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9da3255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.\tRemove all special characters. \n",
    "def remove_special_characters_double_spaces(text):\n",
    "    clean_text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text)\n",
    "    return clean_text\n",
    "zacks_args_df['arguments_clean'] = zacks_args_df['arguments_clean'].apply(remove_special_characters_double_spaces)\n",
    "positive_words_df['Postive_Words'] = positive_words_df['Postive_Words'].apply(remove_special_characters_double_spaces)\n",
    "negative_words_df['Negative_Words'] = negative_words_df['Negative_Words'].apply(remove_special_characters_double_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb5ddb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Postive_Words]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Negative_Words]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#3.\tTokenization. Please use unigram.\n",
    "contains_joiners = positive_words_df['Postive_Words'].str.contains('[_\\-.]')\n",
    "rows_with_joiners = positive_words_df[contains_joiners]\n",
    "print(rows_with_joiners)\n",
    "contains_joiners = negative_words_df['Negative_Words'].str.contains('[_\\-.]')\n",
    "rows_with_joiners = negative_words_df[contains_joiners]\n",
    "print(rows_with_joiners)\n",
    "#The dictonary doesn't contain any word with word joiners, hence not checking the document. Proceeding to the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9030702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word count per description: 415.2234762979684\n"
     ]
    }
   ],
   "source": [
    "#Average length of arguments_clean before stopwords removal (in terms of words)\n",
    "\n",
    "zacks_args_df['word_count_before_sw_removal'] = zacks_args_df['arguments_clean'].apply(lambda x: len(x.split()))\n",
    "average_word_count = zacks_args_df['word_count_before_sw_removal'].mean()\n",
    "print(\"Average word count per description:\", average_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "365368d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word count per description: 262.37697516930024\n"
     ]
    }
   ],
   "source": [
    "#4. Apply stopword list\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_text)\n",
    "zacks_args_df['arguments_clean'] = zacks_args_df['arguments_clean'].apply(remove_stopwords)\n",
    "\n",
    "zacks_args_df['word_count'] = zacks_args_df['arguments_clean'].apply(lambda x: len(x.split()))\n",
    "average_word_count = zacks_args_df['word_count'].mean()\n",
    "print(\"Average word count per description:\", average_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d774a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347\n",
      "2345\n"
     ]
    }
   ],
   "source": [
    "print(len(positive_words_df['Postive_Words']))\n",
    "print(len(negative_words_df['Negative_Words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf10e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words_df['Postive_Words'] = positive_words_df['Postive_Words'].apply(remove_stopwords)\n",
    "negative_words_df['Negative_Words'] = negative_words_df['Negative_Words'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "138c62a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347\n",
      "2345\n"
     ]
    }
   ],
   "source": [
    "print(len(positive_words_df['Postive_Words']))\n",
    "print(len(negative_words_df['Negative_Words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9285a068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ambarella well known market leading high performance video processing socs consume lowest power space companys proprietary video image processing socs highly configurable providing cost power advantage rivals uses multiple expensive semiconductors video image processing solutions makes ambarella suitable choice wearable camera ip camera automotive dashboard cameras drone camera makers move diversify business lower dependency gopro ambarella forayed vr camera space launching h3 soc january year company claims chip work wonderfully highend drones vr cameras although tough ambarella compete well established players nvidia advanced micro believe given track record innovation company potential strengthen position space nearly automakers various stages developing selfdriving cars creating huge demand camera based socs well computer vision technology notably ambarella already deep technical knowledge camerabased socs enhance computer vision capabilities company acquired vislab jul 2015 vislab developed concept computer vision intelligent control systems automotive commercial applications using technology vislab ambarella planning make chips internetconnected security camera companies drone manufacturers initially ambarella may target auto manufacturers'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Before Lemmatization\n",
    "zacks_args_df.loc[0,'arguments_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aa6d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.\tApply Lemmatization\n",
    "# Load the English language model\n",
    "# Make sure to download the model first using: python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def perform_lemmatization(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_sentence = [token.lemma_ for token in doc]\n",
    "    lemmatized_sentence = ' '.join(lemmatized_sentence)\n",
    "    return lemmatized_sentence\n",
    "zacks_args_df['arguments_clean'] = zacks_args_df['arguments_clean'].apply(perform_lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "939ced91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ambarella well know market lead high performance video processing soc consume low power space companys proprietary video image processing soc highly configurable provide cost power advantage rival use multiple expensive semiconductor video image processing solution make ambarella suitable choice wearable camera ip camera automotive dashboard cameras drone camera maker move diversify business low dependency gopro ambarella foray vr camera space launch h3 soc january year company claim chip work wonderfully highend drones vr camera although tough ambarella compete well establish player nvidia advanced micro believe give track record innovation company potential strengthen position space nearly automaker various stage develop selfdrive car create huge demand camera base socs well computer vision technology notably ambarella already deep technical knowledge camerabase socs enhance computer vision capability company acquire vislab jul 2015 vislab develop concept computer vision intelligent control system automotive commercial application use technology vislab ambarella planning make chip internetconnecte security camera company drone manufacturer initially ambarella may target auto manufacturer'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zacks_args_df.loc[0,'arguments_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e007c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Lemmatization to the dictionary\n",
    "positive_words_df['Postive_Words'] = positive_words_df['Postive_Words'].apply(perform_lemmatization)\n",
    "negative_words_df['Negative_Words'] = negative_words_df['Negative_Words'].apply(perform_lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f2e3c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the sentiment score\n",
    "#Convert the positive and negative word lists into sets for faster lookup\n",
    "positive_words = set(positive_words_df['Postive_Words'])\n",
    "negative_words = set(negative_words_df['Negative_Words'])\n",
    "\n",
    "def count_positive_words(text):\n",
    "    return sum(1 for word in text.lower().split() if word in positive_words)\n",
    "\n",
    "def count_negative_words(text):\n",
    "    return sum(1 for word in text.lower().split() if word in negative_words)\n",
    "\n",
    "# Count positive and negative words\n",
    "zacks_args_df['positive'] = zacks_args_df['arguments_clean'].apply(count_positive_words)\n",
    "zacks_args_df['negative'] = zacks_args_df['arguments_clean'].apply(count_negative_words)\n",
    "\n",
    "# Calculate sentiment score using the formula\n",
    "def calculate_sentiment(zacks_args_df):\n",
    "    zacks_args_df['sentiment_score'] = (zacks_args_df['positive'] - zacks_args_df['negative']) / (zacks_args_df['positive'] + zacks_args_df['negative'] + 1)\n",
    "    return zacks_args_df\n",
    "\n",
    "zacks_args_df = calculate_sentiment(zacks_args_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13cfa5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in zacks_args_df where positive > negative: 314\n",
      "Number of records in zacks_args_df where negative > positive: 98\n"
     ]
    }
   ],
   "source": [
    "# Number of records where positive count is greater than negative count in zacks_args_df\n",
    "positive_greater_than_negative = len(zacks_args_df[zacks_args_df['positive'] > zacks_args_df['negative']])\n",
    "\n",
    "# Number of records where negative count is greater than positive count in zacks_args_df\n",
    "negative_greater_than_positive = len(zacks_args_df[zacks_args_df['negative'] > zacks_args_df['positive']])\n",
    "\n",
    "print(\"Number of records in zacks_args_df where positive > negative:\", positive_greater_than_negative)\n",
    "print(\"Number of records in zacks_args_df where negative > positive:\", negative_greater_than_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "433b9744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with sentiment score > 0: 314\n",
      "Number of records with sentiment score < 0: 98\n"
     ]
    }
   ],
   "source": [
    "def count_sentiment_records(df):\n",
    "    positive_sentiment_count = len(df[df['sentiment_score'] > 0])\n",
    "    negative_sentiment_count = len(df[df['sentiment_score'] < 0])\n",
    "    return positive_sentiment_count, negative_sentiment_count\n",
    "# Use the function and print results\n",
    "positive_count, negative_count = count_sentiment_records(zacks_args_df)\n",
    "print(\"Number of records with sentiment score > 0:\", positive_count)\n",
    "print(\"Number of records with sentiment score < 0:\", negative_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bc3c9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment score with Lemmatization and negate\n",
    "\n",
    "negation_words = {'not', 'no', 'never', 'nobody', 'nothing', 'none', 'never', 'hardly', 'scarcely', 'barely'}\n",
    "\n",
    "def calculate_sentiment_with_negation(text, positive_words, negative_words, negation_words):\n",
    "    # Tokenize and lemmatize your text first (assuming it's done outside this function)\n",
    "    tokens = text.split()  # Simple split based on spaces; replace with your lemmatization + tokenization logic\n",
    "\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        word = tokens[i]\n",
    "        if word in negation_words and i + 1 < len(tokens):\n",
    "            next_word = tokens[i + 1]\n",
    "            # Flip the sentiment of the word following the negation\n",
    "            if next_word in positive_words:\n",
    "                negative += 1\n",
    "            elif next_word in negative_words:\n",
    "                positive += 1\n",
    "            i += 2  # Skip the next word as it's already considered\n",
    "        else:\n",
    "            if word in positive_words:\n",
    "                positive += 1\n",
    "            elif word in negative_words:\n",
    "                negative += 1\n",
    "            i += 1\n",
    "\n",
    "    # Calculate the sentiment score considering negation\n",
    "    sentiment_score = (positive - negative) / (positive + negative + 1)\n",
    "    return sentiment_score\n",
    "\n",
    "zacks_args_df['sentiment_score_with_negation'] = zacks_args_df['arguments_clean'].apply(\n",
    "    lambda x: calculate_sentiment_with_negation(\n",
    "        x, \n",
    "        positive_words, \n",
    "        negative_words, \n",
    "        negation_words\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "086a05f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>report_name</th>\n",
       "      <th>ticker</th>\n",
       "      <th>report_date</th>\n",
       "      <th>arguments_clean</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count_before_sw_removal</th>\n",
       "      <th>word_count</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_score_with_negation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ambarella, Inc._Attachment1(2).pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>1/30/2018</td>\n",
       "      <td>ambarella well know market lead high performan...</td>\n",
       "      <td>sell</td>\n",
       "      <td>252</td>\n",
       "      <td>158</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ambarella, Inc._Attachment1(2).pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>6/11/2018</td>\n",
       "      <td>ambarella well know market lead high performan...</td>\n",
       "      <td>sell</td>\n",
       "      <td>257</td>\n",
       "      <td>172</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ambarella, Inc._Attachment1(3).pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>10/30/2018</td>\n",
       "      <td>ambarella make steady progress development del...</td>\n",
       "      <td>buy</td>\n",
       "      <td>472</td>\n",
       "      <td>306</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ambarella, Inc._Attachment1(3).pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>11/26/2020</td>\n",
       "      <td>ambarella make steady progress development del...</td>\n",
       "      <td>sell</td>\n",
       "      <td>442</td>\n",
       "      <td>286</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ambarella, Inc._Attachment1(4).pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>12/3/2018</td>\n",
       "      <td>ambarella make steady progress development del...</td>\n",
       "      <td>buy</td>\n",
       "      <td>472</td>\n",
       "      <td>306</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Ambarella, Inc._Attachment1.pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>6/14/2017</td>\n",
       "      <td>ambarella well know market lead high performan...</td>\n",
       "      <td>buy</td>\n",
       "      <td>438</td>\n",
       "      <td>281</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Ambarella, Inc._Attachment1.pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>1/5/2018</td>\n",
       "      <td>ambarella well know market lead high performan...</td>\n",
       "      <td>buy</td>\n",
       "      <td>437</td>\n",
       "      <td>281</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Ambarella, Inc._Attachment1.pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>6/4/2018</td>\n",
       "      <td>ambarella well know market lead high performan...</td>\n",
       "      <td>buy</td>\n",
       "      <td>429</td>\n",
       "      <td>275</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Ambarella, Inc._Attachment1.pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>9/6/2018</td>\n",
       "      <td>ambarella effort toward expand reach market ip...</td>\n",
       "      <td>sell</td>\n",
       "      <td>504</td>\n",
       "      <td>328</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Ambarella, Inc._Attachment1.pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>11/18/2020</td>\n",
       "      <td>ambarella make steady progress development del...</td>\n",
       "      <td>buy</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                         report_name ticker report_date  \\\n",
       "0   1  Ambarella, Inc._Attachment1(2).pdf   AMBA   1/30/2018   \n",
       "1   2  Ambarella, Inc._Attachment1(2).pdf   AMBA   6/11/2018   \n",
       "2   3  Ambarella, Inc._Attachment1(3).pdf   AMBA  10/30/2018   \n",
       "3   4  Ambarella, Inc._Attachment1(3).pdf   AMBA  11/26/2020   \n",
       "4   5  Ambarella, Inc._Attachment1(4).pdf   AMBA   12/3/2018   \n",
       "5   6     Ambarella, Inc._Attachment1.pdf   AMBA   6/14/2017   \n",
       "6   7     Ambarella, Inc._Attachment1.pdf   AMBA    1/5/2018   \n",
       "7   8     Ambarella, Inc._Attachment1.pdf   AMBA    6/4/2018   \n",
       "8   9     Ambarella, Inc._Attachment1.pdf   AMBA    9/6/2018   \n",
       "9  10     Ambarella, Inc._Attachment1.pdf   AMBA  11/18/2020   \n",
       "\n",
       "                                     arguments_clean label  \\\n",
       "0  ambarella well know market lead high performan...  sell   \n",
       "1  ambarella well know market lead high performan...  sell   \n",
       "2  ambarella make steady progress development del...   buy   \n",
       "3  ambarella make steady progress development del...  sell   \n",
       "4  ambarella make steady progress development del...   buy   \n",
       "5  ambarella well know market lead high performan...   buy   \n",
       "6  ambarella well know market lead high performan...   buy   \n",
       "7  ambarella well know market lead high performan...   buy   \n",
       "8  ambarella effort toward expand reach market ip...  sell   \n",
       "9  ambarella make steady progress development del...   buy   \n",
       "\n",
       "   word_count_before_sw_removal  word_count  positive  negative  \\\n",
       "0                           252         158         9         1   \n",
       "1                           257         172        10         0   \n",
       "2                           472         306        19         1   \n",
       "3                           442         286        21         0   \n",
       "4                           472         306        19         1   \n",
       "5                           438         281        15         1   \n",
       "6                           437         281        15         1   \n",
       "7                           429         275        15         1   \n",
       "8                           504         328        19         1   \n",
       "9                            24          16         1         0   \n",
       "\n",
       "   sentiment_score  sentiment_score_with_negation  \n",
       "0         0.727273                       0.727273  \n",
       "1         0.909091                       0.909091  \n",
       "2         0.857143                       0.857143  \n",
       "3         0.954545                       0.954545  \n",
       "4         0.857143                       0.857143  \n",
       "5         0.823529                       0.823529  \n",
       "6         0.823529                       0.823529  \n",
       "7         0.823529                       0.823529  \n",
       "8         0.857143                       0.857143  \n",
       "9         0.500000                       0.500000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zacks_args_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "689b318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ID, report_name, ticker, report_date, arguments_clean, label, word_count_before_sw_removal, word_count, positive, negative, sentiment_score, sentiment_score_with_negation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "filtered_df = zacks_args_df[zacks_args_df['sentiment_score'] != zacks_args_df['sentiment_score_with_negation']]\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "933d9093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/balubabu/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Sentiment score using NLTK Vader's compound score \n",
    "# Download VADER lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def calculate_sentiment_score_NLTK_Vader(text):\n",
    "    scores = sia.polarity_scores(text)\n",
    "    return scores['compound']\n",
    "    \n",
    "zacks_args_df['sentiment_score_NLTK_Vader'] = zacks_args_df['arguments_clean'].apply(calculate_sentiment_score_NLTK_Vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c72277dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>report_name</th>\n",
       "      <th>ticker</th>\n",
       "      <th>report_date</th>\n",
       "      <th>arguments_clean</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count_before_sw_removal</th>\n",
       "      <th>word_count</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_score_with_negation</th>\n",
       "      <th>sentiment_score_NLTK_Vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ambarella, Inc._Attachment1(2).pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>1/30/2018</td>\n",
       "      <td>ambarella well know market lead high performan...</td>\n",
       "      <td>sell</td>\n",
       "      <td>252</td>\n",
       "      <td>158</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.9776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ambarella, Inc._Attachment1(2).pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>6/11/2018</td>\n",
       "      <td>ambarella well know market lead high performan...</td>\n",
       "      <td>sell</td>\n",
       "      <td>257</td>\n",
       "      <td>172</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.9753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ambarella, Inc._Attachment1(3).pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>10/30/2018</td>\n",
       "      <td>ambarella make steady progress development del...</td>\n",
       "      <td>buy</td>\n",
       "      <td>472</td>\n",
       "      <td>306</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.9969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ambarella, Inc._Attachment1(3).pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>11/26/2020</td>\n",
       "      <td>ambarella make steady progress development del...</td>\n",
       "      <td>sell</td>\n",
       "      <td>442</td>\n",
       "      <td>286</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.9967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ambarella, Inc._Attachment1(4).pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>12/3/2018</td>\n",
       "      <td>ambarella make steady progress development del...</td>\n",
       "      <td>buy</td>\n",
       "      <td>472</td>\n",
       "      <td>306</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.9969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Ambarella, Inc._Attachment1.pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>6/14/2017</td>\n",
       "      <td>ambarella well know market lead high performan...</td>\n",
       "      <td>buy</td>\n",
       "      <td>438</td>\n",
       "      <td>281</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.9931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Ambarella, Inc._Attachment1.pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>1/5/2018</td>\n",
       "      <td>ambarella well know market lead high performan...</td>\n",
       "      <td>buy</td>\n",
       "      <td>437</td>\n",
       "      <td>281</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.9931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Ambarella, Inc._Attachment1.pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>6/4/2018</td>\n",
       "      <td>ambarella well know market lead high performan...</td>\n",
       "      <td>buy</td>\n",
       "      <td>429</td>\n",
       "      <td>275</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.9940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Ambarella, Inc._Attachment1.pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>9/6/2018</td>\n",
       "      <td>ambarella effort toward expand reach market ip...</td>\n",
       "      <td>sell</td>\n",
       "      <td>504</td>\n",
       "      <td>328</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Ambarella, Inc._Attachment1.pdf</td>\n",
       "      <td>AMBA</td>\n",
       "      <td>11/18/2020</td>\n",
       "      <td>ambarella make steady progress development del...</td>\n",
       "      <td>buy</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.6249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                         report_name ticker report_date  \\\n",
       "0   1  Ambarella, Inc._Attachment1(2).pdf   AMBA   1/30/2018   \n",
       "1   2  Ambarella, Inc._Attachment1(2).pdf   AMBA   6/11/2018   \n",
       "2   3  Ambarella, Inc._Attachment1(3).pdf   AMBA  10/30/2018   \n",
       "3   4  Ambarella, Inc._Attachment1(3).pdf   AMBA  11/26/2020   \n",
       "4   5  Ambarella, Inc._Attachment1(4).pdf   AMBA   12/3/2018   \n",
       "5   6     Ambarella, Inc._Attachment1.pdf   AMBA   6/14/2017   \n",
       "6   7     Ambarella, Inc._Attachment1.pdf   AMBA    1/5/2018   \n",
       "7   8     Ambarella, Inc._Attachment1.pdf   AMBA    6/4/2018   \n",
       "8   9     Ambarella, Inc._Attachment1.pdf   AMBA    9/6/2018   \n",
       "9  10     Ambarella, Inc._Attachment1.pdf   AMBA  11/18/2020   \n",
       "\n",
       "                                     arguments_clean label  \\\n",
       "0  ambarella well know market lead high performan...  sell   \n",
       "1  ambarella well know market lead high performan...  sell   \n",
       "2  ambarella make steady progress development del...   buy   \n",
       "3  ambarella make steady progress development del...  sell   \n",
       "4  ambarella make steady progress development del...   buy   \n",
       "5  ambarella well know market lead high performan...   buy   \n",
       "6  ambarella well know market lead high performan...   buy   \n",
       "7  ambarella well know market lead high performan...   buy   \n",
       "8  ambarella effort toward expand reach market ip...  sell   \n",
       "9  ambarella make steady progress development del...   buy   \n",
       "\n",
       "   word_count_before_sw_removal  word_count  positive  negative  \\\n",
       "0                           252         158         9         1   \n",
       "1                           257         172        10         0   \n",
       "2                           472         306        19         1   \n",
       "3                           442         286        21         0   \n",
       "4                           472         306        19         1   \n",
       "5                           438         281        15         1   \n",
       "6                           437         281        15         1   \n",
       "7                           429         275        15         1   \n",
       "8                           504         328        19         1   \n",
       "9                            24          16         1         0   \n",
       "\n",
       "   sentiment_score  sentiment_score_with_negation  sentiment_score_NLTK_Vader  \n",
       "0         0.727273                       0.727273                      0.9776  \n",
       "1         0.909091                       0.909091                      0.9753  \n",
       "2         0.857143                       0.857143                      0.9969  \n",
       "3         0.954545                       0.954545                      0.9967  \n",
       "4         0.857143                       0.857143                      0.9969  \n",
       "5         0.823529                       0.823529                      0.9931  \n",
       "6         0.823529                       0.823529                      0.9931  \n",
       "7         0.823529                       0.823529                      0.9940  \n",
       "8         0.857143                       0.857143                      0.9973  \n",
       "9         0.500000                       0.500000                      0.6249  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zacks_args_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfd95ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of \"Buy\" in the first 100 rows when sorted by sentiment: 0.75\n",
      "Proportion of \"Buy\" in the first 100 rows when sorted by sentiment_with_negate: 0.75\n",
      "Proportion of \"Buy\" in the first 100 rows when sorted by sentiment_NLTK_Vader: 0.88\n"
     ]
    }
   ],
   "source": [
    "#calculating the score\n",
    "def proportion_of_buy(df, sort_column):\n",
    "    # Sort the DataFrame based on a specified column\n",
    "    sorted_df = df.sort_values(by=sort_column, ascending = False)\n",
    "    top_100 = sorted_df.head(100)\n",
    "    proportion = (top_100['label'] == 'buy').mean()\n",
    "    return proportion\n",
    "\n",
    "# Calculate the proportion for each column\n",
    "proportion_sentiment = proportion_of_buy(zacks_args_df, 'sentiment_score')\n",
    "proportion_sentiment_with_negate = proportion_of_buy(zacks_args_df, 'sentiment_score_with_negation')\n",
    "proportion_sentiment_NLTK_Vader = proportion_of_buy(zacks_args_df, 'sentiment_score_NLTK_Vader')\n",
    "\n",
    "print(f'Proportion of \"Buy\" in the first 100 rows when sorted by sentiment: {proportion_sentiment:.2f}')\n",
    "print(f'Proportion of \"Buy\" in the first 100 rows when sorted by sentiment_with_negate: {proportion_sentiment_with_negate:.2f}')\n",
    "print(f'Proportion of \"Buy\" in the first 100 rows when sorted by sentiment_NLTK_Vader: {proportion_sentiment_NLTK_Vader:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a0f08f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
