{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a609bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7ce9d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "startups_df = pd.read_excel('startups.xlsx', sheet_name='Request 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b8840404",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    #converting the text into lower case\n",
    "    text = text.lower() \n",
    "    #remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    #remove the stopwords \n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "    text = ' '.join(filtered_text)\n",
    "    #Apply lemmatization\n",
    "    le=WordNetLemmatizer()\n",
    "    tokens=[le.lemmatize(w) for w in word_tokens if w not in stop_words and len(w)>3]\n",
    "    text = \" \".join(tokens)\n",
    "    return text\n",
    "startups_df['Description'] = startups_df['Description'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "71c7e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TF-IDF vector, apply stop words, keep only 1000 features (1000 columns)\n",
    "vect =TfidfVectorizer(stop_words=list(stop_words),max_features=1000)\n",
    "vect_text=vect.fit_transform(startups_df['Description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd8b8f9",
   "metadata": {},
   "source": [
    "### LDA topic modeling for 3 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e00a0de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 15.493796825408936 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Applying the classical LDA topic-modeling for 3 topics\n",
    "start_time = time.time()\n",
    "lda_model=LatentDirichletAllocation(n_components=3,random_state=42,n_jobs=-1)\n",
    "lda_top=lda_model.fit_transform(vect_text)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "480af46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the predicted topics to the startups dataframe\n",
    "topics = np.argmax(lda_top, axis=1)\n",
    "startups_df['Predicted_Topic'] = None\n",
    "for i in range(0, len(startups_df)):\n",
    "    topic_str = \"Topic\" + str(topics[i])\n",
    "    startups_df.loc[i, 'Predicted_Topic'] = topic_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3dfc687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic2    24808\n",
       "Topic1    17909\n",
       "Topic0    17372\n",
       "Name: Predicted_Topic, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startups_df['Predicted_Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "70584f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Industry Predicted_Topic  Counts  Proportion\n",
      "0  Information Technology          Topic0    4081    0.113557\n",
      "1  Information Technology          Topic1    9278    0.258167\n",
      "2  Information Technology          Topic2   22579    0.628276\n"
     ]
    }
   ],
   "source": [
    "#Finding the most similar topic to the given industry \"Information Technology\"\n",
    "grouped_counts = startups_df.groupby(['Industry', 'Predicted_Topic']).size().reset_index(name='Counts')\n",
    "total_IT_counts = grouped_counts[grouped_counts['Industry'] == 'Information Technology']['Counts'].sum()\n",
    "grouped_counts['Proportion'] = grouped_counts.apply(lambda row: row['Counts'] / total_IT_counts if row['Industry'] == 'Information Technology' else None, axis=1)\n",
    "print(grouped_counts[grouped_counts['Industry'] == 'Information Technology'])\n",
    "#From the below table it is clear that Topic2 is the most similar to Industry Information Technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2e659b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives =  22579\n",
      "False Positives =  2229\n",
      "False Negatives =  13359\n",
      "True Negatives =  21922\n",
      "TP+TN+FP+TN =  60089\n",
      "\n",
      "3-topic Modelling with LDA\n",
      "\n",
      "Precision (for 3-topic LDA) =  0.910149951628507\n",
      "Recall (for 3-topic LDA) =  0.6282764761533752\n"
     ]
    }
   ],
   "source": [
    "#calculating precision and recall of Industry Information Technology\n",
    "\n",
    "tp = grouped_counts[(grouped_counts['Industry'] == 'Information Technology') & (grouped_counts['Predicted_Topic'] == 'Topic2')]['Counts'].sum()#True Postives calculation\n",
    "fp = grouped_counts[(grouped_counts['Industry'] != 'Information Technology') & (grouped_counts['Predicted_Topic'] == 'Topic2')]['Counts'].sum()\n",
    "fn = grouped_counts[(grouped_counts['Industry'] == 'Information Technology') & (grouped_counts['Predicted_Topic'] != 'Topic2')]['Counts'].sum()\n",
    "tn = grouped_counts[(grouped_counts['Industry'] != 'Information Technology') & (grouped_counts['Predicted_Topic'] != 'Topic2')]['Counts'].sum()\n",
    "\n",
    "print(\"True Positives = \", tp)\n",
    "print(\"False Positives = \",fp)\n",
    "print(\"False Negatives = \",fn)\n",
    "print(\"True Negatives = \",tn)\n",
    "print(\"TP+TN+FP+TN = \", tp+tn+fn+fp)\n",
    "\n",
    "#calculate precision\n",
    "precision = tp/(tp+fp)\n",
    "#calculate recall\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(\"\\n3-topic Modelling with LDA\\n\")\n",
    "print(\"Precision (for 3-topic LDA) = \", precision)\n",
    "print(\"Recall (for 3-topic LDA) = \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9d897a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "company product technology system medical development manufacture develops research treatment \n",
      "\n",
      "Topic 1: \n",
      "company service operates engaged business online provides product offer chinabased \n",
      "\n",
      "Topic 2: \n",
      "company software solution platform data provides service user application united \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most important words (top 10) for each topic\n",
    "vocab = vect.get_feature_names_out()\n",
    "\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10] # this is where you change the top 10 to topX\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c84b8c",
   "metadata": {},
   "source": [
    "### LDA topic modelling for 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d9078392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 10.480187892913818 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Applying the classical LDA topic-modeling for 3 topics\n",
    "start_time = time.time()\n",
    "lda_model_2=LatentDirichletAllocation(n_components=10,random_state=42,n_jobs=-1)\n",
    "lda_top_2=lda_model_2.fit_transform(vect_text)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6917a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the predicted topics to the startups dataframe\n",
    "topics2 = np.argmax(lda_top_2, axis=1)\n",
    "startups_df['Predicted_Topic_2'] = None\n",
    "for i in range(0, len(startups_df)):\n",
    "    topic_str = \"Topic\" + str(topics2[i])\n",
    "    startups_df.loc[i, 'Predicted_Topic_2'] = topic_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9f96caa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic7    11304\n",
       "Topic2     8330\n",
       "Topic4     7238\n",
       "Topic3     6905\n",
       "Topic5     4958\n",
       "Topic8     4863\n",
       "Topic0     4452\n",
       "Topic9     4313\n",
       "Topic6     4022\n",
       "Topic1     3704\n",
       "Name: Predicted_Topic_2, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startups_df['Predicted_Topic_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "54304a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Industry2 Predicted_Topic_2  Counts  Proportion\n",
      "30  Computer Software and Services            Topic0    1091    0.070647\n",
      "31  Computer Software and Services            Topic1     784    0.050767\n",
      "32  Computer Software and Services            Topic2    3428    0.221978\n",
      "33  Computer Software and Services            Topic3     277    0.017937\n",
      "34  Computer Software and Services            Topic4     350    0.022664\n",
      "35  Computer Software and Services            Topic5     363    0.023506\n",
      "36  Computer Software and Services            Topic6     159    0.010296\n",
      "37  Computer Software and Services            Topic7    7286    0.471800\n",
      "38  Computer Software and Services            Topic8    1005    0.065078\n",
      "39  Computer Software and Services            Topic9     700    0.045328\n"
     ]
    }
   ],
   "source": [
    "#Finding the most similar topic to the given industry2 \"Computer Software and Services\"\n",
    "grouped_counts_t2 = startups_df.groupby(['Industry2', 'Predicted_Topic_2']).size().reset_index(name='Counts')\n",
    "total_CSS_counts = grouped_counts_t2[grouped_counts_t2['Industry2'] == 'Computer Software and Services']['Counts'].sum()\n",
    "grouped_counts_t2['Proportion'] = grouped_counts_t2.apply(lambda row: row['Counts'] / total_CSS_counts if row['Industry2'] == 'Computer Software and Services' else None, axis=1)\n",
    "print(grouped_counts_t2[grouped_counts_t2['Industry2'] == 'Computer Software and Services']) \n",
    "#From the below table it is clear that Topic7 is the most similar to industry2 \"Computer Software and Services\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5fd2e4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives =  7286\n",
      "False Positives =  4018\n",
      "False Negatives =  8157\n",
      "True Negatives =  40628\n",
      "TP+TN+FP+TN =  60089\n",
      "\n",
      "10-topic modelling with LDA\n",
      "\n",
      "Precision (for 10-topic LDA) =  0.644550601556971\n",
      "Recall (for 10-topic LDA) =  0.4717995208184938\n"
     ]
    }
   ],
   "source": [
    "#calculating precision and recall of industry2 \"Computer Software and Services\"\n",
    "\n",
    "tp2 = grouped_counts_t2[(grouped_counts_t2['Industry2'] == 'Computer Software and Services') & (grouped_counts_t2['Predicted_Topic_2'] == 'Topic7')]['Counts'].sum()#True Postives calculation\n",
    "fp2 = grouped_counts_t2[(grouped_counts_t2['Industry2'] != 'Computer Software and Services') & (grouped_counts_t2['Predicted_Topic_2'] == 'Topic7')]['Counts'].sum()\n",
    "fn2 = grouped_counts_t2[(grouped_counts_t2['Industry2'] == 'Computer Software and Services') & (grouped_counts_t2['Predicted_Topic_2'] != 'Topic7')]['Counts'].sum()\n",
    "tn2 = grouped_counts_t2[(grouped_counts_t2['Industry2'] != 'Computer Software and Services') & (grouped_counts_t2['Predicted_Topic_2'] != 'Topic7')]['Counts'].sum()\n",
    "\n",
    "print(\"True Positives = \", tp2)\n",
    "print(\"False Positives = \",fp2)\n",
    "print(\"False Negatives = \",fn2)\n",
    "print(\"True Negatives = \",tn2)\n",
    "print(\"TP+TN+FP+TN = \", tp2+tn2+fn2+fp2)\n",
    "\n",
    "#calculate precision\n",
    "precision2 = tp2/(tp2+fp2)\n",
    "#calculate recall\n",
    "recall2 = tp2/(tp2+fn2)\n",
    "\n",
    "print(\"\\n10-topic modelling with LDA\\n\")\n",
    "print(\"Precision (for 10-topic LDA) = \", precision2)\n",
    "print(\"Recall (for 10-topic LDA) = \", recall2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6103e41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "company product technology system medical development manufacture develops research treatment \n",
      "\n",
      "Topic 1: \n",
      "company service operates engaged business online provides product offer chinabased \n",
      "\n",
      "Topic 2: \n",
      "company software solution platform data provides service user application united \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most important words (top 10) for each topic\n",
    "vocab = vect.get_feature_names_out()\n",
    "\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10] # this is where you change the top 10 to topX\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec2ca5",
   "metadata": {},
   "source": [
    "### GridSearch CV with LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1645dac2",
   "metadata": {},
   "source": [
    "#### For 3-topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b211308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/balubabu/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4269.514829158783 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "search_params = {'n_components': [5, 10, 15, 30], 'learning_decay': [.5, .9]}\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=3,               # Number of topics\n",
    "                                max_iter=25,               # Max learning iterations\n",
    "                                learning_method='online',   \n",
    "                                random_state=100,          # Random state\n",
    "                                batch_size=128,            # n docs in each learning iter\n",
    "                                evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                n_jobs = -1,               # Use all available CPUs\n",
    "                                )\n",
    "\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "model.fit(vect_text)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b763236b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.9, 'n_components': 5}\n",
      "Best Log Likelihood Score:  -334429.1910823734\n",
      "Model Perplexity:  934.2787310307783\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(vect_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416cf1ae",
   "metadata": {},
   "source": [
    "#### For 10-topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df56e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1033.7638320922852 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "search_params = {'n_components': [5, 10, 15, 30], 'learning_decay': [.5, .9]}\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=10,               # Number of topics\n",
    "                                max_iter=10,               # Max learning iterations\n",
    "                                learning_method='online',   \n",
    "                                random_state=100,          # Random state\n",
    "                                batch_size=128,            # n docs in each learning iter\n",
    "                                evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                n_jobs = -1,               # Use all available CPUs\n",
    "                                )\n",
    "\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "model.fit(vect_text)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90cc0038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.9, 'n_components': 5}\n",
      "Best Log Likelihood Score:  -334578.2370875835\n",
      "Model Perplexity:  937.9188838850542\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(vect_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2bf7aa",
   "metadata": {},
   "source": [
    "3-topic modelling has better model perplexity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
