{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe3280d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93ad4ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/balubabu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5dadf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detecting the encoding of the given file\n",
    "with open('zacks_arguments.csv', 'rb') as file:\n",
    "    sample = file.read(10000)  # Read first 10000 bytes as a sample\n",
    "    detected = chardet.detect(sample)\n",
    "    encoding = detected['encoding']\n",
    "df = pd.read_csv('zacks_arguments.csv', encoding=encoding)\n",
    "#Reading the files into the dataframe\n",
    "zacks_args_df = pd.read_csv('zacks_arguments.csv', encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4779a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the positive and negative word lists into the dataframe \n",
    "column_positive_words = ['Postive_Words']\n",
    "column_negative_words = ['Negative_Words']\n",
    "positive_words_df = pd.read_csv('LM2018P.csv', header=None, names=column_positive_words)\n",
    "negative_words_df = pd.read_csv('LM2018N.csv', header=None, names=column_negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "803ed1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.\tConvert all letters to lowercase\n",
    "zacks_args_df['arguments_clean'] = zacks_args_df['arguments_clean'].str.lower()\n",
    "positive_words_df['Postive_Words'] = positive_words_df['Postive_Words'].str.lower()\n",
    "negative_words_df['Negative_Words'] = negative_words_df['Negative_Words'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9da3255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.\tRemove all special characters. \n",
    "def remove_special_characters_double_spaces(text):\n",
    "    clean_text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text)\n",
    "    return clean_text\n",
    "zacks_args_df['arguments_clean'] = zacks_args_df['arguments_clean'].apply(remove_special_characters_double_spaces)\n",
    "positive_words_df['Postive_Words'] = positive_words_df['Postive_Words'].apply(remove_special_characters_double_spaces)\n",
    "negative_words_df['Negative_Words'] = negative_words_df['Negative_Words'].apply(remove_special_characters_double_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8eb5ddb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Postive_Words]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Negative_Words]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#3.\tTokenization. Please use unigram.\n",
    "contains_joiners = positive_words_df['Postive_Words'].str.contains('[_\\-.]')\n",
    "rows_with_joiners = positive_words_df[contains_joiners]\n",
    "print(rows_with_joiners)\n",
    "contains_joiners = negative_words_df['Negative_Words'].str.contains('[_\\-.]')\n",
    "rows_with_joiners = negative_words_df[contains_joiners]\n",
    "print(rows_with_joiners)\n",
    "#The dictonary doesn't contain any word with word joiners, hence not checking the document. Proceeding to the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a30b896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Apply stopword list\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_text)\n",
    "zacks_args_df['arguments_clean'] = zacks_args_df['arguments_clean'].apply(remove_stopwords)\n",
    "positive_words_df['Postive_Words'] = positive_words_df['Postive_Words'].apply(remove_stopwords)\n",
    "negative_words_df['Negative_Words'] = negative_words_df['Negative_Words'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3aa6d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.\tApply Lemmatization\n",
    "# Load the English language model\n",
    "# Make sure to download the model first using: python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def perform_lemmatization(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_sentence = [token.lemma_ for token in doc]\n",
    "    lemmatized_sentence = ' '.join(lemmatized_sentence)\n",
    "    return lemmatized_sentence\n",
    "zacks_args_df['arguments_clean'] = zacks_args_df['arguments_clean'].apply(perform_lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e007c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Lemmatization to the dictionary\n",
    "positive_words_df['Postive_Words'] = positive_words_df['Postive_Words'].apply(perform_lemmatization)\n",
    "negative_words_df['Negative_Words'] = negative_words_df['Negative_Words'].apply(perform_lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f2e3c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment score with lemmatization and without negate\n",
    "#Convert the positive and negative word lists into sets for faster lookup\n",
    "positive_words = set(positive_words_df['Postive_Words'])\n",
    "negative_words = set(negative_words_df['Negative_Words'])\n",
    "def count_positive_words(text):\n",
    "    return sum(1 for word in text.lower().split() if word in positive_words)\n",
    "def count_negative_words(text):\n",
    "    return sum(1 for word in text.lower().split() if word in negative_words)\n",
    "# Count positive and negative words\n",
    "zacks_args_df['positive'] = zacks_args_df['arguments_clean'].apply(count_positive_words)\n",
    "zacks_args_df['negative'] = zacks_args_df['arguments_clean'].apply(count_negative_words)\n",
    "# Calculate sentiment score using the formula\n",
    "def calculate_sentiment(zacks_args_df):\n",
    "    zacks_args_df['sentiment_score'] = (zacks_args_df['positive'] - zacks_args_df['negative']) / (zacks_args_df['positive'] + zacks_args_df['negative'] + 1)\n",
    "    return zacks_args_df\n",
    "zacks_args_df = calculate_sentiment(zacks_args_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9bc3c9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment score with Lemmatization and negate\n",
    "negation_words = {'not', 'no', 'never', 'nobody', 'nothing', 'none', 'never', 'hardly', 'scarcely', 'barely'}\n",
    "def calculate_sentiment_with_negation(text, positive_words, negative_words, negation_words):\n",
    "    # Tokenize and lemmatize your text first (assuming it's done outside this function)\n",
    "    tokens = text.split()  # Simple split based on spaces; replace with your lemmatization + tokenization logic\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        word = tokens[i]\n",
    "        if word in negation_words and i + 1 < len(tokens):\n",
    "            next_word = tokens[i + 1]\n",
    "            # Flip the sentiment of the word following the negation\n",
    "            if next_word in positive_words:\n",
    "                negative += 1\n",
    "            elif next_word in negative_words:\n",
    "                positive += 1\n",
    "            i += 2  # Skip the next word as it's already considered\n",
    "        else:\n",
    "            if word in positive_words:\n",
    "                positive += 1\n",
    "            elif word in negative_words:\n",
    "                negative += 1\n",
    "            i += 1\n",
    "    # Calculate the sentiment score considering negation\n",
    "    sentiment_score = (positive - negative) / (positive + negative + 1)\n",
    "    return sentiment_score\n",
    "zacks_args_df['sentiment_score_with_negation'] = zacks_args_df['arguments_clean'].apply(\n",
    "    lambda x: calculate_sentiment_with_negation(\n",
    "        x, \n",
    "        positive_words, \n",
    "        negative_words, \n",
    "        negation_words\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "933d9093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/balubabu/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Sentiment score using NLTK Vader's compound score \n",
    "# Download VADER lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "def calculate_sentiment_score_NLTK_Vader(text):\n",
    "    scores = sia.polarity_scores(text)\n",
    "    return scores['compound'] \n",
    "zacks_args_df['sentiment_score_NLTK_Vader'] = zacks_args_df['arguments_clean'].apply(calculate_sentiment_score_NLTK_Vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfd95ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of \"Buy\"s in the first 100 rows when sorted by sentiment (Lemmatization without negate): 75.0\n",
      "Number of \"Buy\"s in the first 100 rows when sorted by sentiment (Lemmatization with negate): 75.0\n",
      "Number of \"Buy\"s in the first 100 rows when sorted by sentiment (NLTK_Vader): 88.0\n"
     ]
    }
   ],
   "source": [
    "#Calculating the propotion of buys predicted correctly for all 3 cases\n",
    "def proportion_of_buy(df, sort_column):\n",
    "    # Sort the DataFrame based on a specified column\n",
    "    sorted_df = df.sort_values(by=sort_column, ascending = False)\n",
    "    top_100 = sorted_df.head(100)\n",
    "    proportion = (top_100['label'] == 'buy').mean()\n",
    "    return proportion\n",
    "# Calculate the proportion for each column\n",
    "proportion_sentiment = proportion_of_buy(zacks_args_df, 'sentiment_score')\n",
    "proportion_sentiment_with_negate = proportion_of_buy(zacks_args_df, 'sentiment_score_with_negation')\n",
    "proportion_sentiment_NLTK_Vader = proportion_of_buy(zacks_args_df, 'sentiment_score_NLTK_Vader')\n",
    "\n",
    "print(f'Number of \"Buy\"s in the first 100 rows when sorted by sentiment (Lemmatization without negate): {proportion_sentiment*100}')\n",
    "print(f'Number of \"Buy\"s in the first 100 rows when sorted by sentiment (Lemmatization with negate): {proportion_sentiment_with_negate*100}')\n",
    "print(f'Number of \"Buy\"s in the first 100 rows when sorted by sentiment (NLTK_Vader): {proportion_sentiment_NLTK_Vader*100}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
